# 운영체제

<details>
<summary><h3>1. 시스템 콜이 무엇인지 설명해 주세요.</h3></summary>
<div markdown="1">     

운영체제에서 제공하는 서비스를 이용하기 위한 프로그래밍 인터페이스이다.<br> 시스템콜의 유형으로는 프로세스 제어, 파일 조작, 장치 조작, 정보 유지보수, 통신과 보호 등으로 나눌 수 있습니다.<br>
사용자 모드에서는 사용자 애플리케이션 코드가 사용되고, 접근할 수 있는 영역에 제한이 있기 때문에 해당 모드에서는 하드웨어(디스크, I/O등)에 직접적으로 접근할 수 없습니다. 접근을 위해서 시스템 콜을 사용하게 됩니다.
- **우리가 사용하는 시스템 콜의 예시를 들어주세요.**<br>
  프로세스 제어를 위한 system call중 다음을 예시로 들 수 있습니다.
  - `fork()`: 자식 프로세스 생성
  - `exec()`: 자신을 수행가능한 다른 프로세스로 대치 수행
  - `wait()`: 프로세스 종료시까지 대기
  - 이외에도 pipe, signal, exit, open, create, close, read, write등이 있습니다.
- **시스템 콜이, 운영체제에서 어떤 과정으로 실행되는지 설명해 주세요.**

  <img width="70%" src="https://user-images.githubusercontent.com/76734067/212707431-a854e8df-61a1-41cf-90cb-335dbc190c3b.png">

  1. 라이브러리 함수(예: printf)를 호출한다.
  2. 라이브러리 함수 내부에서 시스템 콜(write)를 호출한다.
  3. 시스템 콜의 인덱스를 CPU레지스터에 저장한다.
  4. 0x80 인터럽트를 발생시킨다.(커널모드로 전환)
  5. IDT(Interrupt Descriptor Table)을 참조하여 system_call()을 호출한다.
  6. 이때 `3`에서 저장한 인덱스를 system_call()함수 내에 저장한다.
  7. sys_call_table을 참조해 해당 인덱스에 맞는 기능(sys_write)을 호출한다.
  8. 수행이 모두 끝나면 사용자 모드로 전환한다.
- **시스템 콜의 유형에 대해 설명해 주세요.**<br>
  시스템 콜은 다음 6가지로 분류할 수 있습니다.
  - 프로세스 제어
  - 파일 조작
  - 디바이스 조작
  - 정보관리
  - 커뮤니케이션
  - 보안

- **운영체제의 Dual Mode 에 대해 설명해 주세요.**<br>
  이중 동작 모드(Dual-mode Operation)이란 운영체제를 보호하기 위한 기법입니다. 사용자와 운영체제는 시스템 자원을 공유하기 때문에 사용자에게 제한을 주지 않으면 사용자가 메모리 내의 주요 운영체제 자원을 망가뜨릴 위험이 생기게 됩니다. 따라서 시스템 자원 접근을 제한하는 보호장치가 필수적인데 그를 위해서 이중 동작모드를 사용하게 됩니다. **커널 모드**와 **유저 모드**라는 두가지 모드로 나뉘게 됩니다.
  - 커널모드
    - supervisor mode, system mode, privileged mode등으로도 불리운다.
    - 운영체제를 위한 동작을 담당한다.
    - 시스템의 **모든 메모리에 접근**할 수 있고 **모든 CPU명령을 실행**할 수 있다.
    - 운영체제 코드나 디바이스 드라이버 같은 커널모드 코드를 실행한다.
    - CPU는 커널모드 특권 수준에서 코드를 실행한다.
  - 유저모드
    - 사용자를 위한 동작을 담당한다.
    - 사용자 애플리케이션 코드가 실행된다.
    - 시스템 데이터에 **제한된 접근만이 허용**되며 하드웨어를 직접 접근할 수 없다.
    - 유저 애플리케이션에서 시스템 서비스를 호출하면 유저모드에서 커널모드로 전환된다.
    - 유저모드에서 실행하는 스레드는 자신만의 유저모드 스택을 가진다.

- **서로 다른 시스템 콜을 어떻게 구분할 수 있을까요?**<br>
  커널은 내부적으로 각각의 시스템 콜을 구분하기 위해 기능별로 고유번호를 할당하고 그 번호에 해당하는 제어루틴을 커널 내부에 정의하고 있습니다.

</details>

<details>
<summary><h3>2. 인터럽트가 무엇인지 설명해 주세요.</h3></summary>
<div markdown="1">   

CPU가 프로그램을 실행하고 있을 때, 입출력 하드웨어 등의 장치에 예외상황이 발생해서 CPU에게 처리할 수 있도록 알려주는 것.
- **인터럽트는 어떻게 처리하나요?**<br>
  1. 실행하고 있던 프로그램의 실행을 중단합니다.
  2. 현재의 프로그램 상태를 PCB에 보존합니다.
  3. 인터럽트 처리 루틴을 실행합니다.
  4. 인터럽트 서비스 루틴을 실행합니다.
  5. 인터럽트 요청 신호가 발생했을 때 보관한 PC값을 다시 PC에 저장합니다.
  6. PC의 값을 이용하여 인터럽트 발생 이전에 수행중이던 프로그램을 계속 실행합니다.
- **Polling 방식에 대해 설명해 주세요.**<br>
  폴링(Polling)이란 하드웨어장치의 상태를 수시로 체크하여 명령을 받을 수 있는지를 확인하는 것을 말한다.<br>
  - Polling을 하는 동안에는 다른 프로세스에게 CPU를 양도하지 않는다.
  - 하드웨어 장치가 동작을 완료하는 동안 루프를 돌면서 하드웨어의 상태를 체크한다.
  - 하지만 이러한 동작으로 인해서 CPU를 많이 낭비하게 된다.
- **인터럽트와 폴링의 장단점**<br>
  - 인터럽트를 사용하면 CPU연산과 I/O장치 작업을 중첩시켜서 수행할 수 있게 됩니다. 따라서 인터럽트를 사용하는 것이 CPU의 사용률을 높일 수 있습니다.
  - 하지만 인터럽트를 사용하게되면 context switching에서 많은 비용이 수반되기 때문에 단 한번의 폴링으로만 끝날 정도의 빠른 하드웨어 장치라면 폴링이 더 효율적이다.
- **HW / SW 인터럽트에 대해 설명해 주세요.**<br>
  - 하드웨어 인터럽트(외부 인터럽트)
    - 일반적으로 컴퓨터의 하드웨어에서 발생하는 것을 말합니다.
    - 전원의 이상, CPU의 기능 및 기계의 착오, 키보드 동작 또는 입출력 장치의 데이터 전송 등이 있습니다.
  - 소프트웨어 인터럽트(내부 인터럽트)
    - 프로그램 내부에서 발생하는 것으로, 잘못된 명령이나 잘못된 데이터를 사용할 때 발생합니다.
    - Trap이라고도 부릅니다.
    - 허용하지 않은 명령 또는 공간에 접근하거나, 계산결과에 대한 오버플로(Overflow)/언더플로(UnderFlow)등이 있습니다.
</details>

<details>
<summary><h3>3. 프로세스가 무엇인가요?</h3></summary>
<div markdown="1">    

프로세스란 프로그램의 하나의 작업의 단위라고 할 수 있습니다.
- **프로그램과 프로세스, 스레드의 차이에 대해 설명해 주세요.**<br>
  프로세스는 독립된 메모리 영역을 가지는 반면에 스레드는 독립된 메모리 영역을 가지지 않고 같은 프로세스에 속해있는 스레드끼리 stack영역을 제외한 공간을 공유하고 있습니다.
- **PCB가 무엇인가요?**<br>
  PCB는 프로세스의 메타데이터를 저장해놓은 공간입니다. 프로세스에 할당되는 독립적인 메모리 공간과는 별개로 저장됩니다.
- **PCB가 왜 필요한가요?**<br>
  CPU는 프로세스의 상태에 따라 교체작업이 이루어집니다. 이때 교체되는 프로세스의 상태를 기억하기 위해서 프로세스를 정보를 PCB에 저장하게 됩니다. 그리고 새로 불러올 프로세스의 정보를 불러오는데도 필요합니다.
- **PCB는 어떻게 관리되나요?**<br>
  PCB는 링크드리스트 방식으로 관리됩니다. PCB List Head에 PCB들이 생성될 때마다 붙게 됩니다. 주소값으로 연결되어있는 연결리스트이기 때문에 삽입과 삭제가 용이합니다.
- **그렇다면, 스레드는 PCB를 갖고 있을까요?**<br>
  스레드는 PCB를 가지지 않고 스레드의 정보는 TCB(Thread Control Block)에 저장됩니다. Thread별로 존재하는 자료구조이고, PC와 Register Set(CPU)정보 그리고 PCB를 가리키는 포인터를 가집니다. 스레드에 대한 정보만 가지고 있으면 되므로 PCB보다 적은 데이터를 가집니다.
- **리눅스에서, 프로세스와 스레드는 각각 어떻게 생성될까요?**<br>

- **자식 프로세스가 상태를 알리지 않고 죽거나, 부모 프로세스가 먼저 죽게 되면 어떻게 처리하나요?**<br>
  - 자식 프로세스가 종료되었지만 부모프로세스가 자식프로세스의 종료 상태를 회수 하지 않았을 경우에 자식 프로세스를 **좀비프로세스**라고 합니다.
    - 자식프로세스가 종료된 이후에 부모 프로세스가 자식 프로세스의 상태를 알고 싶을 수 있기 때문에 커널은 자식프로세스가 종료되더라도 최소한의 정보(PID, 프로세스 종료상태 등)을 가지고 있게 됩니다.
    - 부모 프로세스가 좀비 프로세스의 종료상태를 회수하게 되면 (wait 시스템 콜을 통하여)좀비 프로세스는 제거됩니다.
    - 좀비 프로세스가 쌓이게 되면 리소스의 유출을 야기할 수 있기 때문에 부모 프로세스는 wait시스템 콜 함수를 사용하여 자식 프로세스의 종료 상태를 읽어들이는 것이 중요합니다.
  - 부모 프로세스가 자식 프로세스보다 먼저 종료되면 자식 프로세스는 **고아프로세스**가 됩니다.
    - 부모 프로세스가 자식 프로세스보다 먼저 종료되면 init프로세스가 자식 프로세스의 새로운 부모 프로세스가 됩니다.
    - 종료되는 프로세스가 발생할 때 커널은 이 프로세스가 누구의 부모 프로세스인지 확인한 후, 커널이 자식프로세스의 부모프로세스 ID를 1(init 프로세스)로 바꾸어줍니다.
    - 고아프로세스가 작업을 종료하면 init프로세스가 wait함수를 호출하여 고아프로세스의 종료상태를 회수함으로써 좀비프로세스가 되는 것을 방지합니다.
- **리눅스에서, 데몬프로세스에 대해 설명해 주세요.**<br>
  - 데몬프로세스란 백그라운드 프로세스 중에서 부모프로세스ID(PPID)가 1이거나 혹은 다른 데몬 프로세스인 프로세스를 말한다.
  - 리눅스의 백그라운드에서 동작하면서 특정한 서비스를 제공하는 프로세스를 말합니다.
  - 대표적인 데몬 프로세스로는 웹서버 데몬이 있습니다. 웹서버 데몬 프로세스는 터미널을 통해서 실행될 수 있지만 터미널을 통해서 사용자와 대화할 필요가 없기 때문에 백그라운드 프로세스로 생성하도록 만들어져 있습니다. 프로그램의 소스 안에서 fork()함수를 통해 자식을 생성하고 부모는 죽습니다. 그리고 생성된 자식은 부모 프로세스를 init프로세스로 변경한 뒤 서비스를 수행할 자식 프로세스를 여러개 fork()하게 됩니다.
</details>

<details>
<summary><h3>4. 프로세스 주소공간에 대해 설명해 주세요.</h3></summary>
<div markdown="1">  

<img width="60%" src="https://user-images.githubusercontent.com/76734067/212748298-17121fc7-8ced-4178-b0b6-a44b5ea9bb3d.png">

프로세스의 주소공간은 대략적으로 Code, Data, Stack, Heap영역으로 나누어집니다.
- Code
  - 프로그램이 실행될 수 있도록 CPU가 해석 가능한 기계어 코드가 위치합니다.
  - 수정되면 안되므로 읽기전용(Read-Only)상태로 저장되어 있습니다.
- Data
  - 전역변수, 정적(static)변수가 저장됩니다.
  - 프로그램 시작과 함께 생성되고, 종료시 소멸된다.
  - 초기화되지 않은 변수가 있다면 BSS영역에 저장된다.
- Stack
  - 함수의 호출과 관계되는 지역변수와 매개변수가 저장되는 영역이다.
  - 메모리의 높은 주소에서 낮은 주소의 방향으로 할당된다.
  - 재귀함수를 많이 호출하거나 지역변수를 너무 많이 가지고 있어 ~~힙 영역을 침범하게 되면~~ 스택영역을 벗어나게 되면 stack overflow가 발생한다.
- Heap
  - 런타임에 크기가 결정되는 영역이다.
  - 사용자에 의해서 공간이 동적으로 할당 및 해제된다.
  - 메모리의 낮은 주소에서 높은 주소의 방향으로 할당된다.
  - 스택영역을 침범하게 되면 heap overflow가 발생한다.

- **초기화 하지 않은 변수들은 어디에 저장될까요?**<br>
  BSS영역에 저장됩니다.
- **일반적인 주소공간 그림처럼, Stack과 Heap의 크기는 매우 크다고 할 수 있을까요? 그렇지 않다면, 그 크기는 언제 결정될까요?**<br>
  Stack의 크기는 생성과 동시에 크기가 정해집니다. 한번 정해지면 바뀌지 않습니다.
- **Stack과 Heap 공간에 대해, 접근 속도가 더 빠른 공간은 어디일까요?**<br>
- **다음과 같이 공간을 분할하는 이유가 있을까요?**<br>
  - 역할의 분배를 위해서 영역을 구분하게 된다. Stack영역을 통해 함수의 흐름을 관리하고 Data 영역을 통해 전역변수와 static변수를 관리하게 된다.
  - 만약 하나의 프로세스가 여러개의 스레드를 갖는다면 각각의 스레드가 Data 영역의 동일한 내용을 공유함으로써 똑같은 공간을 여러개 만들지 않고 메모리를 절약할 수 있다.
- **스레드의 주소공간은 어떻게 구성되어 있을까요?**<br>
  스레드도 자신만의 주소공간을 가지고 있습니다. 하지만 실제로 살펴보면 스레드가 갖고있는 것은 Stack영역밖에 없고 나머지 공간은 프로세스의 값을 함께 써서 다른 스레드와 공유하게 됩니다. 따라서 Data영역에 있는 자원은 동시에 여러 스레드가 접근할 수 있습니다.

</details>

<details>
<summary><h3>5. 단기, 중기, 장기 스케쥴러에 대해 설명해 주세요.</h3></summary>
<div markdown="1"> 

장기스케줄러는 사용할 수 있는 메모리들은 한정되어있는데 많은 프로세스들이 한꺼번에 메모리에 올라올 경우, 디스크에 임시로 저장되게 된다. 여기 저장되어있는 프로세스 중 어떤 프로세스를 Ready Queue로 보낼지 결정하는 역할을 한다. 메모리와 디스크 사이의 스케줄링을 담당하고 프로세스에 메모리를 할당합니다. 실행중인 프로세스의 수(degree of Multiprogramming)을 제어한다는 점이 중요합니다.

단기스케줄러는 메모리에 올라와있는 프로세스 중 어떤 프로세스에게 CPU를 할당할지를 결정합니다. 메모리와 CPU사이의 스케줄링을 담당하고, Ready Queue에 있는 프로세스 중 어떤 프로세스를 running시킬지 결정한다

중기 스케줄러는 여유공간의 마련을 위해 프로세스를 통째로 메모리에서 디스크로 쫓아낸다(swapping), 다른말로하면 프로세스를 메모리에서 해제(deallocated)시킨다. degree of Multiprogramming을 제어하기 위해서 사용한다. 현재 시스템에서 메모리에 너무 많은 프로그램이 올라오는 것을 제어하기 위해서 사용한다.

- **현대 OS에는 단기, 중기, 장기 스케쥴러를 모두 사용하고 있나요?**<br>
  현대의 시분할 시스템에서 사용되는 운영체제에는 일반적으로 장기 스케줄러를 두지 않는 경우가 대부분이다. 과거에는 적은양의 메모리를 많은 프로세스들에게 할당하면 프로세스당 메모리 보유량이 적어져 장기스케줄러가 이를 조절하는 역할을 했지만 현대의 운영체제에서는 프로세스가 시작되면 장기스케줄러 없이 바로 그 프로세스에 메모리를 할당해 준비 큐(Ready Queue)에 넣어주게 된다. 

- **프로세스의 스케쥴링 상태에 대해 설명해 주세요.**<br>
  <img width="70%" src="https://user-images.githubusercontent.com/76734067/212918498-6b8977d3-284e-4a92-b3ed-227e3675d14d.png">
  - `new`: 프로세스 생성 중. 프로세스를 생성하고 있는 단계로, 커널 공간에 PCB가 만들어진 상태이다.
  - `Ready`: 프로세스가 CPU를 기다리는 상태. 프로세스가 메모리에 적재된 상태로, 실행하는데 필요한 자원을 모두 얻은 상태이다.
  - `Running`: 프로세스가 CPU를 할당받아 명령어를 수행중인 상태. 일반적으로 CPU가 하나이기 때문에 여러 프로세스가 동시에 실행되어도 실제로 실행중인 프로세스는 매시점 하나뿐이다.
  - `Waiting`: 프로세스가 어떤 사건(event)가 완료되기를 기다리는 상태. 프로세스가 실행되다가 할당받은 CPU를 반납하고 특별한 event가 완료되길 기다린다.
  - `Terminated`: 프로세스의 실행종료. 프로세스의 실행이 완료되고 할당된 CPU를 반납한다.
  - `Suspended`: 프로세스의 중지 상태. 메모리를 강제로 뺏긴 상태로 특정한 이유로 프로세스의 수행이 정지된 상태를 의미한다. 외부에서 다시 재개시키지 않는 이상 다시 활성화 될수 없다.
    - `suspended ready`: 준비상태(Ready)에 있던 프로세스가 디스크로 스왑 아웃
    - `suspended blocked`: 봉쇄상태(Blocked)에 있던 프로세스가 디스크로 스왑 아웃

- **preemptive/non-preemptive 에서 존재할 수 없는 상태가 있을까요?**<br>
  - ?

- **Memory가 부족할 경우, Process는 어떠한 상태로 변화할까요?**<br>
  메모리가 부족하게 되면 중기 스케줄러에 의해 프로세스 메모리영역의 일부가 디스크로 스왑 아웃되면서 `Suspended`상태로 들어간다.

</details>

<details>
<summary><h3>6. 컨텍스트 스위칭 시에는 어떤 일들이 일어나나요?</h3></summary>
<div markdown="1">  

1. Task의 대부분의 정보는 Register에 저장되고 PCB(Process Control Block)으로 관리된다.
2. 현재 실행하고 있는 Task의 PCB정보를 저장한다.(Process Stack, Ready Queue)
3. 다음에 실행할 Task의 PCB정보를 읽어 Register에 적재하고 CPU가 이전에 진행했던 과정을 연속적으로 수행할 수 있다.

- **그래서 컨텍스트 스위칭이란 무엇인가요?**<br>
  - 프로세스의 상태정보를 저장하고 복원하는 일련의 과정을 말합니다.
- **프로세스와 쓰레드는 컨텍스트 스위칭이 발생했을 때 어떤 차이가 있을까요?**<br>
  - 쓰레드 컨텍스트 스위칭
    - TCS는 CPU가 스레드의 현재 상태를 저장하고 **동일한 프로세스의** 다른 스레드로 전환할 때 발생한다.
    - TCS는 CPU가 여러 스레드를 동시에 처리하도록 도와준다.
    - **스위칭 시에 가져와야 할 내용이 PC값이나 스택등으로 프로세스보다 적어 더 빠르고 저렴하다.**
  - 프로세스 컨텍스트 스위칭
    - PCS는 운영체제의 스케줄러가 실행중인 프로그램의 현재 상태를 저장하고 다른 프로그램으로 전환할 때 발생한다.
    - 실행을 위해 새 프로그램의 상태를 로드하는 것과 관련된다.
    - 작업하는 메모리 주소공간도 전환된다.
    - **독립적인 메모리 공간을 가지므로 캐시메모리를 초기화하는 등 무거운 작업이 진행될 수 있어 TCS에 비해서 상대적으로 느리고, 비용도 많이 든다.**

- **컨텍스트 스위칭이 발생할 때, 기존의 프로세스 정보는 커널스택에 어떠한 형식으로 저장되나요?**<br>
  - ?

- **컨텍스트 스위칭은 언제 일어날까요?**<br>
  1. I/O 인터럽트가 발생했을 때
  2. CPU사용시간이 만료 되었을 때
  3. 자식프로세스가 Fork되었을 때
  4. 인터럽트의 처리를 기다릴 때(?)

</details>

<details>
<summary><h3>7. 프로세스 스케줄링 알고리즘에는 어떤 것들이 있나요?</h3></summary>
<div markdown="1">  

[다음 페이지](https://github.com/January1st-98/Swift/blob/main/cs/operating-system.md#cpu-%EC%8A%A4%EC%BC%80%EC%A4%84%EB%9F%AC)에 정리해두었습니다.<br>
FCFS, SJF, SRTF, Priority-Scheduling, Round-Robin(RR)등이 있습니다.

- **RR을 사용할 때, Time Slice에 따른 trade-off를 설명해 주세요.**<br>
  - Time Slice가 짧아질수록 사용자 반응성이 좋아지지만 context switching이 발생하기 때문에 그만큼 오버헤드가 많이 소모된다.
  - Time Slice가 너무길어지면 FCFS 알고리즘과 다를바 없어진다. 사용자 반응성도 그만큼 줄어들게 된다.
- **싱글 스레드 CPU 에서 상시로 돌아가야 하는 프로세스가 있다면, 어떤 스케쥴링 알고리즘을 사용하는 것이 좋을까요? 또 왜 그럴까요?**<br>

- **동시성과 병렬성의 차이에 대해 설명해 주세요.**<br>
  동시성은 작업이 끝나기를 기다리고 처리하는지, 아니면 작업이 끝나는 것을 기다리지 않는것의 문제이고, 병렬성은 작업을 하나의 스레드에서 처리할 지, 여러개의 스레드에서 처리할지에 대한 것이다.
- **Multi-level Feedback Queue**가 무엇인가요?
  - [멀티 레벨 피드백 큐](https://velog.io/@jewelrykim/%EB%A9%80%ED%8B%B0-%EB%A0%88%EB%B2%A8-%ED%94%BC%EB%93%9C%EB%B0%B1-%ED%81%90%EC%9A%B0%EC%84%A0%EC%88%9C%EC%9C%84-%EC%8A%A4%EC%BC%80%EC%A5%B4%EB%A7%81)
- **타 스케쥴러와 비교하여, Multi-level Feedback Queue는 어떤 문제점들을 해결한다고 볼 수 있을까요?**<br>
  1. 짧은 작업을 먼저 실행시켜 반환시간을 최적화 하고자 하였다.<br>
    SJF, STCF같은 알고리즘은 작업의 실행시간정보를 필요로 하지만, 운영체제 입장에서는 작업의 실행시간에 대한 정보를 미리 알 수 없다.
  2. MLFQ를 통해 대화형 사용자에게 응답이 빠른 시스템이라는 느낌을 주고자 하였다.<br>
    RR은 응답시간은 단축시키지만 반환시간은 거의 최악이였기 때문이다.

</details>

<details>
<summary><h3>8. 뮤텍스와 세마포어의 차이점은 무엇인가요?</h3></summary>
<div markdown="1">  

1. 가장 큰 차이점은 뮤텍스는 동기화 대상이 되는 자원이 하나라면, 세마포어는 하나이상의 자원에서 사용가능하다는 점 입니다. Mutex는 상태가 0과 1인 이진 세마포어라고 볼 수 있습니다.
2. 세마포어는 소유할 수 없는 반면, 뮤텍스는 소유가 가능하고 소유주가 이에 대한 책임을 집니다.
3. Mutex는 Locking매커니즘으로 locking을 걸은 쓰레드만이 Ciritical Section을 나갈 때 락을 해제할 수 있다. 하지만 세마포어는 Signaling 매커니즘으로 lock을 걸지 않은 쓰레드도 signal을 사용해서 락을 해제할 수 있다.
4. 세마포어는 시스템 범위에 걸쳐 있고 파일 시스템 상의 파일 형태로 존재하지만, 뮤텍스는 프로세스 범위를 가지며 프로세스가 종료될 때 자동으로 해제된다.

- **이진 세마포어와 뮤텍스의 차이에 대해 설명해 주세요.**<br>
  이진 세마포어는 0, 1값만을 가지는 세마포어를 말합니다. 값이 두개밖에 없기 때문에 뮤텍스와 차이가 없어보이지만 뮤텍스는 lock을 설정한 프로세스만이 lock을 해제할 수 있다. 하지만 이진 세마포어의 경우 lock을 설정한 프로세스와 해제하는 프로세스가 다를 수 있다.

</details>

<details>
<summary><h3>9. Deadlock 에 대해 설명해 주세요.</h3></summary>
<div markdown="1">  

- **Deadlock 이 동작하기 위한 4가지 조건에 대해 설명해 주세요.**<br>
- **그렇다면 3가지만 충족하면 왜 Deadlock 이 발생하지 않을까요?**<br>
- **어떤 방식으로 예방할 수 있을까요?**<br>
- **왜 현대 OS는 Deadlock을 처리하지 않을까요?**<br>
- **Wait Free와 Lock Free를 비교해 주세요.**<br>

</details>

<details>
<summary><h3>10. 프로그램이 컴파일 되어, 실행되는 과정을 간략하게 설명해 주세요.</h3></summary>
<div markdown="1">  

- **링커와, 로더의 차이에 대해 설명해 주세요.**<br>
- **컴파일 언어와 인터프리터 언어의 차이에 대해 설명해 주세요.**<br>
- **JIT에 대해 설명해 주세요.**<br>
- **본인이 사용하는 언어는, 어떤식으로 컴파일 및 실행되는지 설명해 주세요.**<br>

</details>

<details>
<summary><h3>11. IPC가 무엇이고, 어떤 종류가 있는지 설명해 주세요.</h3></summary>
<div markdown="1">  
<ul>
<li> Shared Memory가 무엇이며, 사용할 때 유의해야 할 점에 대해 설명해 주세요.</li>
<li> 메시지 큐는 단방향이라고 할 수 있나요?</li>
</ul>
</details>

<details>
<summary><h3>12. Thread Safe 하다는 것은 어떤 의미인가요?</h3></summary>
<div markdown="1">  
<ul>
<li> Thread Safe 를 보장하기 위해 어떤 방법을 사용할 수 있나요?</li>
<li> Peterson's Algorithm 이 무엇이며, 한계점에 대해 설명해 주세요.</li>
<li> Race Condition 이 무엇인가요?</li>
</ul>
</details>

<details>
<summary><h3>13. Thread Pool, Monitor, Fork-Join에 대해 설명해 주세요.</h3></summary>
<div markdown="1">  
<ul>
</ul>
</details>

<details>
<summary><h3>14. 캐시 메모리 및 메모리 계층성에 대해 설명해 주세요.</h3></summary>
<div markdown="1">  
<ul>
<li> 캐시 메모리는 어디에 위치해 있나요?</li>
<li> L1, L2 캐시에 대해 설명해 주세요.</li>
<li> 캐시에 올라오는 데이터는 어떻게 관리되나요?</li>
<li> 캐시간의 동기화는 어떻게 이루어지나요?</li>
<li> 캐시 메모리의 Mapping 방식에 대해 설명해 주세요.</li>
<li> 캐시의 지역성에 대해 설명해 주세요.</li>
<li> 캐시의 지역성을 기반으로, 이차원 배열을 가로/세로로 탐색했을 때의 성능 차이에 대해 설명해 주세요.</li>
</ul>
</details>

<details>
<summary><h3>15.메모리의 연속할당 방식 세 가지를 설명해주세요. (first-fit, best-fit, worst-fit)</h3></summary>
<div markdown="1">  
<ul>
<li> worst-fit 은 언제 사용할 수 있을까요?</li>
<li> 성능이 가장 좋은 알고리즘은 무엇일까요?</li>
</ul>
</details>

<details>
<summary><h3>16. Thrashing 이란 무엇인가요?</h3></summary>
<div markdown="1">  
<ul>
<li> Thrashing 발생 시, 어떻게 완화할 수 있을까요?</li>
</ul>
</details>

<details>
<summary><h3>17. 가상 메모리란 무엇인가요?</h3></summary>
<div markdown="1">  
<ul>
<li> 가상 메모리가 가능한 이유가 무엇일까요?</li>
<li> Page Fault가 발생했을 때, 어떻게 처리하는지 설명해 주세요.</li>
<li> 페이지 크기에 대한 Trade-Off를 설명해 주세요.</li>
<li> 페이지 크기가 커지면, 페이지 폴트가 더 많이 발생한다고 할 수 있나요?</li>
</ul>
</details>

<details>
<summary><h3>18. 세그멘테이션과 페이징의 차이점은 무엇인가요?</h3></summary>
<div markdown="1">  
<ul>
<li> 페이지와 프레임의 차이에 대해 설명해 주세요.</li>
<li> 내부 단편화와, 외부 단편화에 대해 설명해 주세요.</li>
<li> 페이지에서 실제 주소를 어떻게 가져올 수 있는지 설명해 주세요.</li>
<li> 어떤 주소공간이 있을 때, 이 공간이 수정 가능한지 확인할 수 있는 방법이 있나요?</li>
<li> 32비트에서, 페이지의 크기가 1kb 이라면 페이지 테이블의 최대 크기는 몇 개일까요?</li>
</ul>
</details>

<details>
<summary><h3>19. TLB는 무엇인가요?</h3></summary>
<div markdown="1">  
<ul>
<li> TLB를 쓰면 왜 빨라지나요?</li>
<li> MMU가 무엇인가요?</li>
<li> TLB와 MMU는 어디에 위치해 있나요?</li>
</ul>
</details>

<details>
<summary><h3>20. 동기화를 구현하기 위한 하드웨어적인 해결 방법에 대해 설명해 주세요.</h3></summary>
<div markdown="1">  
<ul>
<li> volatile 키워드는 어떤 의미가 있나요?</li>
<li> 싱글코어가 아니라 멀티코어라면, 어떻게 동기화가 이뤄질까요?</li>
</ul>
</details>

<details>
<summary><h3>21. 페이지 교체 알고리즘에 대해 설명해 주세요.</h3></summary>
<div markdown="1">  
<ul>
<li> LRU 알고리즘은 어떤 특성을 이용한 알고리즘이라고 할 수 있을까요?</li>
<li> LRU 알고리즘을 구현한다면, 어떻게 구현할 수 있을까요?</li>
</ul>
</details>

<details>
<summary><h3>22. File Descriptor와, File System에 에 대해 설명해 주세요.</h3></summary>
<div markdown="1">  
<ul>
<li> I-Node가 무엇인가요?</li>
</ul>
</details>

<details>
<summary><h3>23. 동기와 비동기, 블로킹과 논블로킹의 차이에 대해 설명해 주세요.</h3></summary>
<div markdown="1">  
<ul>
<li> 그렇다면, 동기이면서 논블로킹이고, 비동기이면서 블로킹인 경우는 의미가 있다고 할 수 있나요?</li>
<li> I/O 멀티플렉싱에 대해 설명해 주세요.</li>
</ul>
</details>
